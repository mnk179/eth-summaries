\documentclass[11pt,oneside,a4paper]{article}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{lscape}
\usepackage{psfrag}
\usepackage[usenames]{color}
\usepackage{bbm}
\usepackage[update]{epstopdf}
\usepackage[bookmarks,pdfstartview=FitH,a4paper,pdfborder={0 0 0}]{hyperref}
\usepackage{verbatim}
\usepackage{listings}
\usepackage{textcomp}
\usepackage{fancyhdr}
\usepackage{multirow}
\usepackage{tikz}
\usepackage{lipsum}
\usepackage{xcolor}
\usepackage{wrapfig}
\usepackage[margin=1in]{geometry}
\newcommand{\hint}[1]{{\color{blue} \em #1}}

\makeatletter
\def\cleardoublepage{\clearpage\if@twoside \ifodd\c@page\else%
\hbox{}%
\thispagestyle{empty}%
\clearpage%
\if@twocolumn\hbox{}\clearpage\fi\fi\fi}
\makeatother

\sloppy
% \widowpenalty=10000
% \clubpenalty=10000

\title{
    \vspace*{0.0mm}
    \LARGE\bf\sf Advanced Topics in \\Communication Networks (Fall 2019)
    \vspace*{10.0mm} \\
    %
    \Huge\bf\sf Summary
    %
    \vspace*{30.0mm} \\
    \normalsize
    %
    \sf Author:\\[5pt]
    \sf Yannick Merkli\\ [5pt]
    \sf \pageref{lastpage} Pages
}
\date{}

\begin{document}

\maketitle
\thispagestyle{empty}
\raggedbottom
\clearpage

\pagenumbering{roman}

\clearpage
\setcounter{tocdepth}{2}
\tableofcontents
\clearpage
\pagenumbering{arabic}

\section{Introduction}

Networking is on the verge of a paradigm shift towards deep programmability.

\subsection{The network managment crisis}
Networks are large distributed systems running a set of distributed algorithms. These algorithms produce the forwarding state which drives IP traffic to its destination. Operators adapt their network behavior by configuring each network device individually. This is extremely tedious and error-prone with a single mistyped line being enough to bring down an entire network (fat-thumbing). Further, the complexity in networks keeps increasing with more and more protocols appearing, a lot of which are badly documented (read an RFC and find out).

\subsection{Software-defined networking (SDN)}

SDN tries to design network control and is predicated around two simple concepts: (1) Separate the control-plane from the data-plane. (2) Provide an API to directly access the data-plane.\\
In traditional computer networks, each networked device has a local control-plane. SDN allows to have a central control-plane, controlling multiple networked devices at once. This has several advantages: (1) Simpler management, (2) Faster pace of innovation, (3) Easier interoperability, (4) Simpler, cheaper equipment. Having a common open, vendor-agnostic interface enables a control plane to control forwarding devices from different hardware and software vendors. OpenFlow does exactly this: OpenFlow is essentially an API to a switch flow table. The OpenFlow interface started simple, with the abstraction of a single table of rules that could match packets on a dozen header fields (e.g., MAC addresses, IP addresses, protocol, TCP/UDP port numbers, etc.). Over the past five years, the specification has grown increasingly more complicated, with many more header fields and multiple stages of rule tables, to allow switches to expose more of their capabilities to the controller. So essentially, the OpenFlow protocol became too complex.

\subsection{Deep network programmability}

Deep network programmability tries to adopt the good ideas of OpenFlow while solving its shortcomings. OpenFlow's problem is that it's  not flexible enough for a highly dynamic environment such as networking, with constantly changing protocols and specifications.
Future switches should support flexible mechanisms for parsing packets and matching header fields, allowing controller applications to leverage these capabilities through a common, open interface. Recent chip desings show that such flexibility can be achieved in custom ASICs at terabit speeds.

\begin{figure}[hb]
	\centering
	\includegraphics[width=0.75\textwidth,scale=1]{figures/PISA}
	\caption{Protocol Independent Switch Architecture (PISA) for high-speed programmable packet forwarding. \cite{advnet}}
	\label{fig:PISA}
\end{figure}

\newpage

\begin{figure}%[hb]
	\centering
	\begin{subfigure}[t]{.5\textwidth}
		\centering
		\includegraphics[width=\linewidth]{figures/P4_overview}
		\label{fig:P4_overview}
	\end{subfigure}%
	\begin{subfigure}[t]{.5\textwidth}
		\centering
		\includegraphics[width=\linewidth]{figures/P4_openflow}
		\label{fig:P4_openflow}
	\end{subfigure}
	\caption{P4 is a language to configure switches. \cite{bosshart2014p4}}
\end{figure}


Each chip has its own low-level interface, however this might vary for different hardware. Ideally we would want a higher-level language which can be used to configure a switch. This is exactly what P4 (Programming Protocol-independent Packet Processors) does: P4 is a higher-level language which is used to configure a switch, telling it how packets are to be processed. P4 can further be used with existing APIs (such as OpenFlow) that are designed to populate the forwarding tables in fixed function switches.

\section{The P4 programing language}

P4 raises the level of abstraction for programming the network, and can serve as a general interface between the controller and the switches. As such, P4 tries to achieve the following three main goals:
\vspace{-\topsep}
\begin{itemize}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
	\item Reconfigurability. The controller should be able to redefine the packet parsing and processing in the field.
	\item Protocol independence. The switch should be able to specify (i) a packet parser (ii) a collection of match-action tables that process theses headers.
	\item Target independence. The P4 program should run on various hardware with the compiler producing the target-dependent program.
\end{itemize}
\vspace{-\topsep}

\noindent A P4 program consists of three basic parts: Parser, match-action pipeline, deparser. In this course, we rely on a simple $P4_{16}$ switch architecture (v1model).

\begin{figure}[hb]
	\centering
	\begin{subfigure}[t]{.5\textwidth}
		\centering
		\includegraphics[width=\linewidth]{figures/forwarding_model}
		\caption{The abstract P4 forwarding model. \cite{bosshart2014p4}}
		\label{fig:forwarding_models}
	\end{subfigure}%
	\begin{subfigure}[t]{.5\textwidth}
		\centering
		\includegraphics[width=\linewidth]{figures/match_action_tables}
		\caption{Reconfigurable match-action table. \cite{advnet}}
		\label{fig:match_action_tables}
	\end{subfigure}
\end{figure}

\newpage

\noindent The forwarding model is controlled by two types of operations: Configure and Populate. Configure operations program the parser, set the order of match + action stages, and specify the header fields processed by each stage. Configuration determines which protocols are supported and how the switch may process packets. Populate operations add (and remove) entries to the match-action tables that were specified during configuration. Population determines the policy applied to packets at any given time.

\subsection{Language specification}
\subsubsection{Data types}

$P4_{16}$ is a statically typed language with base types and operators to derive composed ones. Base types are:

\begin{center}
	\begin{tabular}{ |c|c| } 
		\hline
		bool & Boolean value \\ 
		\hline
		bit\textless W\textgreater & Bit-string of width W \\ 
		\hline
		int\textless W\textgreater & Signed integer of width W \\ 
		\hline
		varbit\textless W\textgreater & Bit-string of dynamic length $\leq W$ \\
		\hline
		match\textunderscore kind & describes ways to match table keys \\
		\hline
		error & used to signal errors \\
		\hline
		void & no values, used on few restricted instances \\
		\hline
	\end{tabular}
\end{center}
\noindent Note that there are no floats or strings.\newline

Headers are composed operators. Headers are similar to structs in C, containing different fields. Parsing a packet using \texttt{extract()} fills in the fields of the header from a network packet. Headers further have a hidden "validity" field which is set to true upon a successful \texttt{extract()}.

\begin{figure}[hb]
	\centering
	\includegraphics[width=0.75\textwidth,scale=1]{figures/headers}
	\label{fig:headers}
	\cite{advnet}
\end{figure}

\subsubsection{Operations}\label{operations}

P4 operations are similar to C operations and vary depending on the types (unsigned/signed ints, ...). However there is no division or modulo.

Constants, variable declarations and instantiations are pretty much the same as in C too. However, Variables have local scope and their values is not maintained across subsequent invocations. This is due to the fact that the code will be rerun for every new packet. We thus cannot use variables as states since they will be erased for each subsequent run of the code. In order to maintain state, you have to use tables or extern objects.

\subsubsection{Statements}

P4 statements are pretty classical too:  
\vspace{-\topsep}
\begin{itemize}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
	\item return
	\item exit
	\item \texttt{if()\{...\} else \{...\}} (not in parsers)
	\item \texttt{switch (t.apply.action\_run) \{ a1: \{...\} a2: \{...\}\}} (only in control blocks)
\end{itemize}
\vspace{-\topsep}

\noindent Loops do not exist in P4 (with one exception, see \ref{parser})

\subsection{Parser}\label{parser}

The parser uses a state machine to map packets into headers and metadata. Parsing a header stack requires the parser to loop. This is the only 'loops' that are possible in P4. 

Defining (and parsing) \textit{custom} headers allow you to implement your own protocol. This is why OpenFlow didn't work well in reality and P4 does: with P4, companies can just define their own protocols (for example ETH and UZH can establish a common tunneling protocol). With OpenFlow, companies were either bound to existing protocols and headers or, in case of a influential company, they could bring up new protocols which were eventually implemented in OpenFlow and available to everyone, even though only a small subset of people need that protocol. This led to OpenFlow becoming the overblown beast it is today.

\subsection{Match-action tables}

Match-action tables are the mechanism for performing packet processing. The P4 program defines the fields on which a table may match and the actions it may execute.

\noindent Tables can match on one or multiple keys in different ways:
\vspace{-\topsep}
\begin{itemize}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
	\item \texttt{exact}: exact comparison (0x01020304)
	\item \texttt{ternary}: compare with mask (0x01020304 \& 0x0F0F0F0F)
	\item \texttt{lpm}: longest prefix match (0x01020304/24)
	\item \texttt{range}: check if in range	(0x01020304 — 0x010203FF)
\end{itemize}
\vspace{-\topsep}

\noindent Table entries are added through the control plane.\newline
Example: \texttt{table\_add ipv4\_lpm ipv4\_forward 1.2.3.0/24 => 01:01:01:01:01:01 1}

The match-action tables are divided between ingress and egress. While both may modify the packet header, ingress match-action determines the egress port(s) and determines the queue into which the packet is placed. Based on ingress processing, the packet may be forwarded, replicated (for multicast, span, or to the control plane), dropped, or trigger flow control. Egress match-action performs per-instance modifications to the packet header – e.g., for multicast copies.

Packets can carry additional information between stages, called metadata, which is treated identically to packet header fields. Some examples of metadata include the ingress port, the transmit destination and queue, a timestamp that can be used for packet scheduling, and data passed from table-to-table that does not involve changing the parsed representation of the packet such as a virtual network identifier.

\subsection{Actions}

Actions are blocks of statements that possibly modify the packets (think of them as functions in C). P4 supports the construction of complex actions from simpler protocol-independent primitives. Actions can either be invoked from within a control block or as a result of a match in a match-\textit{action}-table.

\newpage

\noindent Actions that are invoked from within a control block take directional parameters, indicating how the corresponding value is treated within the block.
\vspace{-\topsep}
\begin{itemize}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
	\item \texttt{in}: parameters in only read inside the action (like parameters to a function)
	\item \texttt{out}: parameter is uninitialized and will be written to inside the action (like return values)
	\item \texttt{inout}: combination of in and out (like “call by reference”)
\end{itemize}


\noindent Action parameters resulting from a table lookup do not take a direction as they come from the control plane.

\subsection{Control flow}

Control flow consists of various concepts, for an extensive list, please consider \cite{p416spec}. Some basic concepts are:
\vspace{-\topsep}
\begin{itemize}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
	\item applying a table: \texttt{ipv4\_lpm.apply()}
	\item Checking if there was a hit: \texttt{if (ipv4\_lpm.apply().hit) \{...\}}
	\item Check which action was executed: \texttt{switch (ipv4\_lpm.apply().action\_run) \{...\}}
\end{itemize}

\noindent Other often used concepts are: 
\vspace{-\topsep}
\begin{itemize}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
	\item re-computing checksums (needs to be done when changing a packet, otherwise the kernel will drop packets upon checksum mismatch)
	\item cloning packets
	\item sending packets to control plane (using dedicated Ethernet port, or target-specific mechanisms (e.g. digests))
\end{itemize}



\subsection{Stateful objects}

As mentioned in section \ref{operations}, variables have local scope and their value is not maintained across subsequent invocations. In order to build stateful apps, we thus need stateful objects. Match-action tables are one way of achieving persistent state, however the P4 \textit{v1model} offers more stateful objects as externs. 

\subsubsection{Registers}

Registers are assigned in arrays and are useful for storing (small amounts of) arbitrary data. We can read from and write to a specified register index in an array of registers. Further, registers can be read from the control plane.
The syntax works as follows:\newline
\indent \texttt{register<bit<48>>(16384) last\_seen; bit<48> last\_pkt\_ts;} \newline
\indent \texttt{last\_seen.read(last\_pkt\_ts, flow\_id);} \newline
\indent \texttt{last\_seen.write(flow\_id, standard\_metadata.ingress\_global\_timestamp);} \newline
\noindent Registers can be used to build a stateful firewall, for example.

\subsubsection{Counters}

Counters are for counting (unsurprisingly). A counter can be increased from the data plane \textit{but} can only be read from the control plane. Like registers, counters are assigned in arrays and an index needs to be specified when executing a \texttt{count()} operation.
Counters can be one of three different types: packets, bytes, packet\_and\_bytes (each type counts what it specifies to count). The syntax works as follows:\newline
\indent \texttt{counter(512, CounterType.packets\_and\_bytes) port\_counter;} \newline
\indent \texttt{port\_counter.count((bit<32>)standard\_metadata.ingress\_port);} \newline
\noindent Reading from the control plane: \newline
\indent \texttt{RuntimeCmd: counter\_read MyIngress.port\_counter 1} \newline
\indent \texttt{MyIngress.port\_counter[1]= BmCounterValue(packets=13, bytes=1150)}

\newpage

\noindent Direct counters are a specially kind of counters that are attached to tables. We can specify a counter in the table definition and thus attach it to the table. Then, each table entry has a counter cell that counts when the entry matches. \newline
\indent \texttt{direct\_counter(CounterType.packets\_and\_bytes) direct\_port\_counter;} \newline
\indent \texttt{table count\_table \{} \newline
\indent \indent ... \newline
\indent \indent counters = direct\_port\_counters; \newline
\indent \}

\subsubsection{Meters}

Meters are used for rate-limiting. Meters 'color' flows into green, yellow and red (see two-rate three-color meters, RFC2698). We have two threshold rates: the committed information rate (CIR) and the peak information rate (PIR). Green flows neither exceed the CIR nor the PIR. Yellow flows exceed the CIR but don't exceed the PIR. Red flows exceed the PIR. Like counters, meters can be one of three different types: packets, bytes, packet\_and\_bytes and they are assigned in arrays. And just like for counters, we also have direct meters which can be attached to tables. The syntax looks as follows:

\indent \texttt{meter(32w16384, MeterType.packets) my\_meter;} \newline
\indent	\texttt{my\_meter.execute\_meter<bit<32>>(meter\_index, meta.meter\_tag); //action}\\

\noindent Executing the meter will yield one of 3 values: 0 (GREEN), 1 (YELLOW) or 2 (RED). This value will be copied to metadata field meta.meter\_tag

\begin{figure}[t!]
	\centering
	\begin{subfigure}[t]{.33\textwidth}
		\centering
		\includegraphics[width=1\textwidth,scale=1]{figures/registers}
		\caption{P4 registers \cite{advnet}}
		\label{fig:registers}
	\end{subfigure}%
	\begin{subfigure}[t]{.33\textwidth}
		\centering
		\includegraphics[width=1\textwidth,scale=1]{figures/counters}
		\caption{P4 counters \cite{advnet}}
		\label{fig:counters}
	\end{subfigure}
	\begin{subfigure}[t]{.33\textwidth}
		\centering
		\includegraphics[width=1\textwidth,scale=1]{figures/meters}
		\caption{P4 meters \cite{advnet}}
		\label{fig:meters}
	\end{subfigure}
\end{figure}

\begin{figure}[b!]
	\centering
	\includegraphics[width=0.6\textwidth,scale=1]{figures/stateful_objects_summary}
	\caption{Stateful objects summary. 	\cite{advnet}}
	\label{fig:stateful_objects_summary}
\end{figure}

\subsection{Hash functions}

P4 \textit{v1model} offers hash functions: \newline
\texttt{enum HashAlgorithm\{crc32,crc32\_custom,crc16,s,random,identity,csum16,xor16\}} \newline
\texttt{extern void hash<O,T,D,M>(out O result, in HashAlgorithm algo, in T base, in D data, in M max);}

\newpage

\section{Probabilistic data structures}

P4 provides us with built-in stateful data structures such as arrays of registers, counters or meters. However, with these we need to deal with severe limitations such as limited number of operations and memory. That's why we consider more advanced stateful data structures.

\subsection{Bloom filter}

We want a data structure for insertion and membership queries. In order to get a deterministic number of required operations, the data structure should be probabilistic. A simple approach would be a basic fixed size table with $M$ 1-bit cells for $N$ elements. If we observe an element, we hash it and set the bit at the corresponding index to 1. Due to hash collision ($N > M$), we get a false positive rate of $FPR = 1 - (1-\frac{1}{M})^N$. The advantage of this approach is that only one operation is required per insertion or query. However, roughly 100x more cells are required than the number of element we want to store for a 1\% false positive rate. \newline

Bloom filters are a more memory-efficient approach for insertions and membership queries. Bloom filters consist of a fixed size table \texttt{bf} with $M$ 1-bit cells and $K$ hash functions and we write a 1 at each position indicate by each hash function.

\begin{figure}[hb]
	\begin{minipage}[t]{.5\textwidth} 
		\vspace{0pt}
		\centering 
		\includegraphics[width=0.45\textwidth]{figures/bloom_filter}
		\caption{Bloom filter. 	\cite{advnet}}
		\label{fig:bloom_filter}
	\end{minipage} 
	\begin{minipage}[t]{.5\textwidth} 
		\vspace{10pt} 
		\begin{itemize}
			\setlength{\itemsep}{0pt}
			\setlength{\parskip}{0pt}
			\item Insert \textit{e} into \texttt{bf}: 
				\begin{enumerate}
					\item $\forall i \in [1,K]$, calculate $h_i(e)$
					\item $\texttt{bf}[h_i(e)] = 1, \forall i \in [1,K]$
				\end{enumerate}
			\item Membership query \textit{e}:
				\begin{enumerate}
					\item if $\texttt{bf}[h_i(e)] == 1, \forall i \in [1,K]$ 
					\newline $\rightarrow$ $e$ is in \texttt{bf}
					\item else 
					\newline $\rightarrow$ $e$ is not in \texttt{bf}
				\end{enumerate}
			\end{itemize}
	\end{minipage} 
\end{figure}

The advantage of bloom filters is that they use about 10x less memory than the simple approach. However, they require slightly more operations.

\subsubsection{Dimension your bloom filter}
\label{bloom_filter_dimension}

$N$ elements, $M$ cells, $K$ hash functions, $FP$ false positive rate.

\vspace{-\topsep}
\begin{itemize}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
	\item probability that one hash function returns the index of a particular cell: $\frac{1}{M}$
	\item probability that one hash function does not return the index of a particular cell: $1 - \frac{1}{M}$
	\item probability of a cell to be 0: $(1 - \frac{1}{M})^{KN}$
	\item false positive rate P(FP): $(1 - (1 - \frac{1}{M})^{KN})^K$
	\item false negative rate: 0
\end{itemize}
\vspace{-\topsep}

\noindent For an approximation, use: $p := P(FP) = (1 - (1 - \frac{1}{M})^{KN})^K \approxeq (1 - e^{-KN/M})^K$. \newline

\noindent $FN = 0$ since if we have seen an element once, all cells corresponding to its hashes will have been set to 1. Since we never delete elements, $FN = 0$. If we were to delete elements from a bloom filter (i.e. set all cells corresponding to an element to 0), false negatives would be possible.
Because deletions are not possible, the controller may need to regularly reset the bloom filter. Resetting a bloom filter takes some time during which it is not usable. A common trick is to use two bloom filters and use one when the controller resets the other one.

\newpage

\noindent We can't just keep increasing $K$ to lower $FP$ since for too many hash functions, we will have lots of 1s in the table and a lower chance of finding 0s, which increases $FP$. 

\noindent There's a global minimum when $K = \ln(2) * \frac{M}{N}  \approx 0.7*\frac{M}{N}$, found by taking derivative of $P(FP)$. For that choice of $K$, resulting $p := P(FP) = 2^{-K} \approx 0.6185^{M/N}$.\\
Given optimal $K$, choice of optimal $M = -\frac{N \ln p}{(\ln2)^2}$ $\rightarrow O(N)$ space.

\begin{figure}[hb]
	\centering
	\includegraphics[width=0.55\textwidth,scale=1]{figures/bloom_filter_p4}
	\caption{Bloom filter with $K = 2$ hash functions implemented in $P4_{16}$. \cite{advnet}}
	\label{fig:bloom_filter_p4}
\end{figure}

\subsection{Counting bloom filter}

Since we cannot delete items from a bloom filter, we extend them to handle deletions. For counting bloom filters, to add an element, increment the corresponding counters by 1. The cells are thus no longer 1-bit but larger. To delete an element, decrement the corresponding counters by 1. An element is considered in the table if all counters are larger than 0. All of our prior analysis for standard bloom filters applies to counting bloom filters. We still have $FN = 0$ since a counter of a cell only reaches 0 if all elements mapped to that cell were deleted. Unless we have counter overflow. If a counter gets too large and wraps around to 0, false negatives are possible. Counters must be large enough to avoid overflow. Poisson approximation suggests 4 bits/counter.

Thus, Counting Bloom Filters do handle deletions at the price of using more memory
\vspace{0pt}
\begin{figure}[b!]
	\begin{minipage}[t]{.5\textwidth} 
		\vspace{0pt}
		\centering 
		\includegraphics[width=0.45\textwidth]{figures/counting_bloom_filter}
		\caption{Counting bloom filter. \cite{advnet}}
		\label{fig:counting_bloom_filter}
	\end{minipage} 
	\begin{minipage}[t]{.5\textwidth} 
		\vspace{10pt} 
		\begin{itemize}
			\setlength{\itemsep}{0pt}
			\setlength{\parskip}{0pt}
			\item Insert \textit{e} into \texttt{cbf}: 
			\begin{enumerate}
				\item $\forall i \in [1,K]$, calculate $h_i(e)$
				\item $\texttt{cbf}[h_i(e)] \mathrel{+}= 1, \forall i \in [1,K]$
			\end{enumerate}
			\item Membership query \textit{e}:
			\begin{enumerate}
				\item if $\texttt{bf}[h_i(e)] \geq 1, \forall i \in [1,K]$ 
				\newline $\rightarrow$ $e$ is in \texttt{cbf}
				\item else 
				\newline $\rightarrow$ $e$ is not in \texttt{cbf}
			\end{enumerate}
		\end{itemize}
	\end{minipage} 
\end{figure}

\newpage

\subsection{Invertible Bloom Lookup Tables (IBLT)}

Invertible Bloom Lookup Tables (IBLT) stores key-value pairs and allows for lookups and a complete listing. Each cell contains three fields:

\vspace{-\topsep}
\begin{itemize}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
	\item count: counts the number of entries mapped to this cell
	\item keySum: the sum of all keys mapped to this cell
	\item valueSum: the sum of all the values mapped to this cell
\end{itemize}
\vspace{-\topsep}

\noindent In many settings, we can use XORs in place of sums, for example to avoid overflow issues.

\begin{center}
	\begin{tabular}{ |p{75mm}|p{75mm}| } 
		\hline
		Add a new key-value pair & Delete a key-value pair (assuming it's in set) \\ 
		\hline
		for each hash function & for each hash function\\
		\hspace{3mm} hash the key to find the index & \hspace{3mm} hash the key to find the index \\
		\hspace{3mm} then at this index & \hspace{3mm} then at this index \\
		\hspace{6mm} \textbf{increment} the count by one & \hspace{6mm} \textbf{substract} one from the count \\
		\hspace{6mm} \textbf{add} key to keySum & \hspace{6mm} \textbf{substract} key from keySum \\
		\hspace{6mm} \textbf{add} value to valueSum & \hspace{6mm} \textbf{substract} value from valueSum \\
		\hline
	\end{tabular}
\end{center}

\noindent The value of a key can be found if the key is associated to \textbf{at least} one cell without a hash collision, i.e. a cell with $count = 1$ (see \ref{fig:iblt_lookup}).

\begin{center}
	\begin{tabular}{ |p{100mm}| } 
		\hline
		Listing the IBLT \\
		\hline
		\textbf{While} there is an index for which count = 1 \\
		\hspace{3mm} \textbf{Find} the corresponding key-value pair and return it \\
		\hspace{3mm} \textbf{Delete} the corresponding key-value pair \\
		\hline
	\end{tabular}
\end{center}

\noindent A complete listing is not possible if there is a key that has $count > 1$ at each cell indicated by the hash of the key. Unless the number of iterations is very low, loops can’t be implemented in hardware. The listing is done by the controller.

\begin{figure}[hb]
	\centering
	\begin{subfigure}[t]{.33\textwidth}
		\centering
		\includegraphics[width=1\textwidth,scale=1]{figures/iblt_1}
		\caption{IBLT insert key:7, value:98}
		\label{fig:iblt_insert}
	\end{subfigure}%
	\begin{subfigure}[t]{.33\textwidth}
		\centering
		\includegraphics[width=1\textwidth,scale=1]{figures/iblt_2}
		\caption{IBLT lookup key:7}
		\label{fig:iblt_lookup}
	\end{subfigure}
	\begin{subfigure}[t]{.33\textwidth}
		\centering
		\includegraphics[width=1.25\textwidth,scale=1]{figures/iblt_3}
		\caption{IBLT delete key:7,  value:98}
		\label{fig:iblt_delete}
	\end{subfigure}
	\caption{Invertible Bloom Lookup Tables (IBLT) insertion and lookup \cite{advnet}}
\end{figure}

\newpage

\subsection{Sketches}

Bloom filters allow us to do efficient insertion and membership queries at the cost of false positives. This way we can quickly filter only those elements that might be in the set. However, this is often not enough for monitoring use cases. We also want to approximate frequencies of elements in a data stream. Again, we use probabilistic measures which make this more efficient by allowing miscounting.

\subsubsection{CountMin sketch}

A CountMin sketch uses the same principles as a counting bloom filter, but is designed to have provable L1 error bounds for frequency queries. We use the following notation: a vector of frequencies (counts) of all distinct elements $x_i$: $\vec{x} = [x_1, x_2, ...]^T$.

$$Pr[\hat{x_i} - x_i \geq \epsilon ||\textbf{x}||_1] \leq \delta$$

\noindent with $\hat{x_i}$: estimated frequency, $x_i$: true frequency, $||\textbf{x}||_1$: sum of frequencies.\newline

\noindent A CountMin Sketch uses multiple arrays and hashes. Let $d$ be the number of arrays, with one hash function per array and $w$ indices per array (range of hashes). We thus have $w*d$ counters. CountMin sketches are essentially Bloom filters where we increase the counter at each position indicated by the hashes. Hash collisions can cause over-counting.

\begin{center}
	\begin{tabular}{ |p{75mm}|p{75mm}| } 
		\hline
		Count a new element & Lookup the count of an element \\ 
		\hline
		for each hash function & for each hash function\\
		\hspace{3mm} hash the element to find the index & \hspace{3mm} hash the element to find the index \\
		\hspace{3mm} then at this index & \hspace{3mm} then at this index \\
		\hspace{6mm} \textbf{increment} the count by one & \hspace{6mm} \textbf{lookup} the count \\
		& return the min count \\
		\hline
	\end{tabular}
\end{center}

\begin{figure}[hb]
	\centering
	\includegraphics[width=0.5\textwidth,scale=1]{figures/countminsketch_recipe}
	\caption{CountMin sketch recipe, with \textit{e}: Euler's number \cite{advnet}}
	\label{fig:countminsketch_recipe}
\end{figure}

\begin{figure}[b!]
	\centering
	\begin{subfigure}[t]{.5\textwidth}
		\centering
		\includegraphics[width=0.7\textwidth,scale=1]{figures/countminsketch_count}
		\label{fig:countminsketch_count}
	\end{subfigure}%
	\begin{subfigure}[t]{.5\textwidth}
		\centering
		\includegraphics[width=0.7\textwidth,scale=1]{figures/countminsketch_lookup}
		\label{fig:countminsketch_lookup}
	\end{subfigure}
	\caption{CountMin sketches count and lookup \cite{advnet}}
\end{figure}

\newpage

\begin{figure}[t!]
	\centering
	\includegraphics[width=0.7\textwidth,scale=1]{figures/sketches}
	\caption{CountMin sketch and Count sketch \cite{advnet}}
	\label{fig:sketches}
\end{figure}

\subsubsection{Count sketch}

A Count sketch uses the same principles as a counting bloom filter, but is designed to have provable L2 error bounds for frequency queries. The Count sketch uses additional hashing to give L2 error bounds, but requires more resources.

\begin{figure}[hb]
	\centering
	\includegraphics[width=0.5\textwidth,scale=1]{figures/countsketch_recipe}
	\caption{Count sketch recipe \cite{advnet}}
	\label{fig:countsketch_recipe}
\end{figure}

\newpage

\section{P4 hardware targets}

How can we allow network programmability in the field, at reasonable cost, and without sacrificing speed. Let's look at a concrete design: Reconfigurable Match Tables (RMT) \cite{rmt}. This paper argues that flexibility does not come at the price of performance or cost.\\
Let's first look at a fixed-function switch composed of a (de-)parser and a sequence of processing stages. In such a switch, each stage is particularized to its usage. This specificity makes it impossible to trade memory size for another, add a new table, support new headers or new actions.

\begin{figure}[hb]
	\centering
	\includegraphics[width=0.5\textwidth,scale=1]{figures/fixed_function_switch}
	\label{fig:fixed_function_switch}
\end{figure}

\noindent SDN wants multiple stages of match-action (flexible allocation), flexible actions and flexible header fields (OpenFlow was designed with these goals in mind). Alternative ways to enable flexibility don't compare in terms of cost-performance ratio: software is 100x too slow and expensive, NPUs are 10x too slow and expensive and FPGAs are 10x to slow and expensive.\\

The solution to all these problems are \textbf{Reconfigurable Match Tables (RMT)}. However, this is challenging to achieve. What kind of switch architecture could support flexibility and yet run at Terabits per second.  At 1Tbps, packet size of 1000bits and 10 operations per packet, we'd need 10 billion operations per second. With a single processor, this would require a 10Ghz processor, which is not feasible. Parallelizing things with a packet-parallel architecture allows to have lower CPU speeds through duplication of the processing units. However, one issue is to scale the memory-to-CPU bandwidth. Replicating memory comes at a huge cost in die area.\\
\noindent The solution is to organize the processing as a pipeline. Pipelined architectures organize processing through a sequence of processing units and local memory. For flexibility, each processing unit/memory can be made generic. Each CPU can process distinct packets, with up to 10 packets going through the pipeline simultaneously.

\begin{figure}[hb]
	\centering
	\begin{subfigure}[t]{.5\textwidth}
		\centering
		\includegraphics[width=0.9\textwidth,scale=1]{figures/switch_pipeline}
		\caption{Pipeline switch architecture}
		\label{fig:switch_pipeline}
	\end{subfigure}%
	\begin{subfigure}[t]{.5\textwidth}
		\centering
		\includegraphics[width=0.9\textwidth,scale=1]{figures/matchaction_forwarding_model}
		\caption{Match/Action Forwarding Model}
		\label{fig:matchaction_forwarding_model}
	\end{subfigure}
\end{figure}

\newpage

\subsection{Parsing}

Parsing is the (complex) process of identifying and extracting the appropriate fields in a packet header. Parsing faces multiple challenges:

\vspace{-\topsep}
\begin{itemize}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
	\item Throughput: Parser must run at line-rate (parse 1 packet every 70ns on a 10Gbps link)
	\item Dependency: Parsing involves sequential processing as headers typically point to the next
	\item Incompleteness: Some headers do not even identify the subsequent headers
	\item Heterogeneity: Many header formats exist that can appear in various orders/locations
\end{itemize}
\vspace{-\topsep}

\noindent Parse graphs are directed acyclic graphs encoding header types and their sequence. A parser can be divided into two separate blocks: header identification and field extraction. In a programmable parser, the two modules rely on runtime information (stored in memory, e.g. in RAM and/or TCAM) instead of hard-coded logic.

\begin{figure}[hb]
	\centering
	\includegraphics[width=0.7\textwidth,scale=1]{figures/hardware_parser}
	\caption{Programmable hardware parser}
	\label{fig:hardware_parser}
\end{figure}

\subsection{Logical pipeline}

A compiler translates a given RMT logical pipeline (specified in P4) into a physical one. Each physical stage contains dedicated SRAM, for exact matches, and TCAM, for ternary matches. The compiler maps each individual logical stage to one or more physical stage. Small tables can share a stage (up to 16 per stage), while large tables can span multiple ones.\\

\begin{figure}[hb]
	\centering
	\begin{subfigure}[t]{.5\textwidth}
		\centering
		\includegraphics[width=0.9\textwidth,scale=1]{figures/rmt_logical_pipeline}
		\label{fig:rmt_logical_pipeline}
	\end{subfigure}%
	\begin{subfigure}[t]{.5\textwidth}
		\centering
		\includegraphics[width=0.9\textwidth,scale=1]{figures/rmt_physical_stages}
		\label{fig:rmt_physical_stages}
	\end{subfigure}
	\caption{Logical pipeline \cite{gibb2013design}}
\end{figure}

\newpage

\noindent The RMT pipeline relies on many Arithmetic Logic Units (ALU) to perform actions on the result of a match. Each ALU modifies only one word of a header (a header is composed of many words). Each stage of the RMT pipeline contains one ALU per word of the header vector (that's a lot of ALUs).

\begin{figure}[hb]
	\centering
	\begin{subfigure}[t]{.5\textwidth}
		\centering
		\includegraphics[width=0.7\textwidth,scale=1]{figures/action_processing_model}
		\label{fig:rmt_logical_pipeline}
	\end{subfigure}%
	\begin{subfigure}[t]{.5\textwidth}
		\centering
		\includegraphics[width=0.7\textwidth,scale=1]{figures/multi_action_processing}
		\label{fig:rmt_physical_stages}
	\end{subfigure}
	\caption{Logical pipeline \cite{gibb2013design}}
\end{figure}

\noindent Building a RMT pipeline is only 15\% more expensive than building a fixed-function switching pipeline. The biggest cost is the memory not the processing logic.\\
In conclusion, we can design a flexible chip using the RMT switch model, bring processing close to the memories (pipeline of many stages) and bring processing to the wires (224 action CPUs per stage). This only causes a 15\% cost increase.











\label{lastpage} % this must stay here
\clearpage
\addcontentsline{toc}{section}{References}
\bibliographystyle{acm}
\bibliography{refs}

\clearpage
\appendix
\pagenumbering{Roman}

\end{document}
